<html lang="bg">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Основна част</title>
  <link rel="stylesheet" href="../Assets/css/style.css">
  <style>
    body {
      font-family: "Arial", sans-serif;
    }
    footer {
      margin-top: 2rem;
      padding: 1rem;
      text-align: center;
      background-color: #b99272;
      color: white;
    }
    .footer-nav {
      margin-top: 1rem;
    }
    .footer-nav a.button {
      margin: 0 0.5rem;
    }
  </style>
</head>
<body>
  <header>
    <h1>Основна част</h1>
  </header>

  <main>
    <div class="nav-buttons">
      <a href="../index.html" class="button">Начална страница</a>
      <a href="intro.html" class="button">Въведение</a>
      <a href="literature.html" class="button">Използвана литература</a>
    </div>

    <section class="section">
      <h2>2. Видове машинно обучение</h2>
      <p>Машинното обучение представлява процес, при който компютърни системи извличат модели данни с целта да вземат решения или да предскажат бъдещи резултати. В зависимост от наличието на предварително означени (етикирани) данни. Етикирани данни са данни при които за всяко наблюдение е известен правилен отговор или категория. Както отбелязва Нилсон (Nils Nilsson), машинното обучение се е превърнало в един от най-важните дялове на изкуствения интелект включващ методи като ръководено обучение (Supervised), неръководено обучение (Unsupervised) и подкрепено обучение (Reinforcement) [1]. Други междинни начини на обучения като полу-ръководена (Semi-supervised) и само-ръководено (self-supervised) съществуват но те добиват популярност след публикуването на „The Quest for Artificial Intelligence“ през 2009 г. в книги като например „The Deep Learning Book“ излязла 2016 г.</p>

      <h3>2.1 Ръководено обучение (Supervised Learning)</h3>
      <p>Ръководеното обучение е най-традиционната и интуитивна форма на машинно обучение, при която на алгоритъма се предоставят входни примери, съпроводени с техните правилни изходи (етикети). Основната цел е да се научи обобщаваща функция, която може да предсказва правилния изход за нови, невиждани досега входове. Според Нилсън, този тип обучение може да се разглежда като функционално приближение, при което моделът се стреми да доближи възможно най-много реалната зависимост между вход и изход [1].</p>
      <p>Примери: Използва се за класифициране на имейли като „спам“ или „не спам“ според съдържанието им.</p>
      <p>Примерни алгоритми:</p>
      <ul>
        <li>Решаващи дървета (Decision Trees) - Илюстрират логически пътища към дадено решение чрез поредица от въпроси [1].</li>
        <li>Невронни мрежи (Neural Networks) - структури от взаимосвързани единици, които учат от множество примери [1].</li>
      </ul>

      <h3>2.2 Полу-ръководено обучение (Semi-Supervised Learning)</h3>
      <p>Полу-ръководеното обучение комбинира предимствата на ръководеното и неръководеното обучение, като използва голямо количество неетикирани данни и малко на брой етикирани. Основната идея е, че дори ограничената наличност на ръчно означени примери може да бъде значително подсилена чрез използването на допълнителни, неетикирани входове. Това прави метода особено ценен в практиките, про които етикетирането е скъпо, бавно или изисква намесата на експерт.</p>
      <p>Пример: При разпознаване на ръкописни цифри от вида MNIST, могат да се използват хиляди не етикирани изображения и само няколко ръчно означени.</p>
      <p>Методи:</p>
      <ul>
        <li>Генеративни модели като: Variational Autoencoders и Generative Adversarial Networks за изграждане на вътрешно представяне на входа [2].</li>
        <li>Consistency training: идеята, че предсказанията не трябва да се променят съществено при малко модификации на входа [2].</li>
        <li>Такива подходи позволяват обучение с висока точност дори при оскъдна наличност на етикирани примери, което е особено ценно в реални случаи, където анотацията е скъпа или трудоемка [2].</li>
      </ul>

      <h3>2.3 Само-ръководено обучение (Self-Supervised Learning)</h3>
      <p>Само-ръководеното обучение е модерен подход, при който самият модел генерира свои цели за обучение, извличайки сигнали от структурата на входните данни. Това позволява обучение без ръчно означени етикети и дава възможност за използване на изключително големи набори от сурови данни.</p>
      <p>Пример: Модел предсказва липсваща част от изображение или дума в текст (например BERT и NLP) [2].</p>
      <p>Методи: Автоенкодери, контрастивно обучение, трансформъри в езиковото моделиране и др. [2].</p>

      <h3>2.4 Неръководено обучение (Unsupervised Learning)</h3>
      <p>Неръководеното обучение се използва в ситуации, при които входните данни нямат предварително зададени етикети или категории. В този случай, целта на алгоритъма е самостоятелно да открие структура, закономерности или вътрешни зависимости в данните, без помощта на външна информация. Вместо да се учи как предсказва конкретен изход, както е при ръководеното обучение, тук системата се стреми да разбере как са организирани данните.</p>
      <p>Пример: Сегментиране на клиенти по пазарно поведение [1].</p>
      <p>Алгоритми: K-средни стойности (K-Means) - оптимизира разстоянията между наблюденията и центровете на клъстери [1].</p>

      <h3>2.5 Подкрепено обучение (Reinforcement Learning)</h3>
      <p>Подкрепеното обучение се отличава от останалите форми по това, че ученето се осъществява чрез взаимодействие със среда, а не чрез готови етикети. В този модел, агентът изпълнява действия и получава награди или наказания, в зависимост от последиците на действията му. Основната цел е изграждане на стратегия (или политика), която да води до максимално натрупване на възнаграждение с времето. Този подход е особено приложим при последователни решения във време, където всяко действие не само оказва влияние върху текущото състояние, но и променя бъдещите възможности [1].</p>
      <p>Пример: Обучение на робот да се придвижва без сблъсъци. В процеса на обучение, агентът трябва да балансира между две поведения: експлорация (Изпробване на нови действия за събиране на информация) и екплотация (използване на вече научена стратегия за постигане на максимална награда. Този баланс е ключов за успешно самообучение в динамични среди [1].</p>
      <p>Методи: Q-learning, времеви разлики (TD learning), политико-базирани методи [1]</p>
    </section>

    <section class="section">
      <h2>3. Самообучение и самообучаващи се системи</h2>
      <p>Самообучението е процес, при който една интелигентна система подобрява своето поведение въз основа на опита си, без да разчита на предварително зададени правилни отговори. В основата на този подход стои идеята, че машината може сама да извлича информация от неструктурирани или частично структурирани данни, използвайки обратна връзка от околната среда или собствената си структура.</p>

      <h3>3.1 Самообучение и агентно поведение</h3>
      <p>В изкуствения интелект терминът интелигентен агент обозначава система, която възприема среда, взема решения и изпълнява действия с цел постигане на опредени цели. Когато агентът е способен да се адаптира на база опит, говорим за самообучаваща се система. Това е типично за  подкрепеното обучение, където агентът взаимодейства със среда, получава награди или наказания и усъвършенства стратегията си така, че да максимизира бъдещата възвръщаемост.</p>
      <p>Пример: Нилсън (Nillson)  описва как „роботизиран плъх“ се учи да намира пътя през лабиринт, използвайки методи като Q-learning. С всяко преминаване той получава информация за полезността на различни действия, изграждайки стратегия на основа на опит, а не на предварително зададено знание [1].</p>

      <h3>3.2 Самообучение чрез структури в данните</h3>
      <p>Самообучението не се ограничава само до взаимодействие със средата. В контекста на representation learning, системите могат да се обучават чрез самогенерирани задачи. Като автоенкодерите и контрастивното обучение използват не етикирани входове, за да предскажат липсващи части от тях или да различават сходни и различни примери. В книгата на Goodfellow се подчертава, че такива методи позволяват на модела да извлича абстрактни представяния, които са полезни дори при ограничено количество етикетирана информация [2].</p>
      <p>Пример: Системата може да се „учи“ като опитва да реконструира изображение от частично закрита версия. Това се разглежда като форма на само-ръководено обучение, при която самият модел си създава задача чрез трансформация на входа [2].</p>
    </section>

    <section class="section">
      <h2>4. Приложения на самообучаващи се системи</h2>
      <p>Самообучаващи се системи намират широко приложение в различни области, където етикетирането на данни е трудно, скъпо, невъзможно, или където средата изисква непрекъсната адаптация. Тези системи се отличават със способността си да извличат знания чрез взаимодействие със среда или чрез самоорганизиране на представяния от сурови данни. Тук ще разглеждаме няколко от най-характерните приложения на самообучението в практиката.</p>

      <h3>4.1 Автономни агенти и роботи</h3>
      <p>В областта на роботиката самообучението позволява на интелигентни агенти да развива поведение чрез натрупване на опит. Вместо да бъдат предварително програмирани, те се учат да вземат решения въз основа на последиците от собствените си действия. Пример за това е обучението на един агент да избягва препятствия в динамична среда, като чрез награди той постепенно усвоява стратегия за безопасно придвижване. Нилсън описва как системи могат да се обучават чрез обратна връзка от средата, без човешки инструкции, което е основен принцип на подкрепеното обучение (reinforcement learning) [1].</p>

      <h3>4.2 Обработка на изображения</h3>
      <p>В сферата на компютърните изображения, самообучението се използва за извличане на визуални представяния чрез задачи като реконструкция на изображение, предсказване на следващ кадър или разграничаване между подобни и различни изображения. Такива подходи намаляват зависимостта от ръчно означени примери и често водят до по-добра обобщаемост. Goodfellow et al. описва автоенкодерите като средство за изграждане на вътрешни представяния чрез възстановяване на входа от частично загубена информация [2].</p>

      <h3>4.3 Системи за препоръки</h3>
      <p>Препоръчващите системи, използвани в платформи като YouTube и Netflix, се възползват от самообучаващи се алгоритми за персонализиране. Когато потребителят взаимодейства с дадено съдържание, системата използва наблюдаваното поведение като основа за обучение и подобряване на следващите препоръки. Това често се реализира чрез подкрепено обучение (reinforcement learning). Целта на прилагането на подкрепено обучение в тези системи не е просто да се предложи съдържание, което ще бъде избрано веднага, а да се максимизира дългосрочната ангажираност на потребителя. [3], [4].</p>
    </section>

    <section class="section">
      <h2>5. Заключение</h2>
      <p>Машинното обучение и самообучение са сред най-динамично развиващите се области в изкуствения интелект. Те предлагат решения, които заменят ръчното програмиране със способността на машините да се усъвършенстват чрез опит, взаимодействие или структурни зависимости в данните. От класическите видове, разгледани от Нилсън [1], до съвременните дълбоки архитектури, описани от Goodfellow et al. [2], развитието на обучителни системи преминава през етапи на все по-висока автономност и гъвкавост. </p>
        <p>Самообучаващите се алгоритми вече намират реално приложения. От препоръчващи системи, които оптимизират потребителското преживяване [3], [4], до модели, които извличат вътрешни представи от текст, изображения или поведение без нуждата от ръчно означени данни. Този напредък отваря врати към системи, които не просто изпълняват задачи, а се адаптират, развиват и самоусъвършенстват.</p>
    </section>
</main>

<div class="nav-buttons" style="margin-top: 2rem;">
    <a href="../index.html" class="button">Начална страница</a>
    <a href="intro.html" class="button">Въведение</a>
    <a href="literature.html" class="button">Използвана литература</a>
  </div>

  <footer>
    
  &copy; 2025 Виктор Христов Атанасов | Русенски университет „Ангел Кънчев“
</footer>
</body>
</html>
